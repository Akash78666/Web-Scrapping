{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7355428c-3075-441e-9d61-865a7bb38cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data?\n",
    "Ans:-Web scraping is the process of collecting structured web data in an automated manner. It's also widely known as web data extraction or web data scraping. Some of the main use cases of web scraping include price monitoring, price intelligence, news monitoring, lead generation, and market research among many others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a549c821-02ce-4d93-9c45-0b6e35782fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. What are the different methods used for Web Scraping?\n",
    "Ans:-Google Sheets is a popular tool for data scraping. Scarpers can use the IMPORTXML function in Sheets to scrape from a website, which is useful if they want to extract a specific pattern or data from the website. This command also makes it possible to check if a website can be scraped or is protected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ebfb84-9c11-4c4e-ae86-9d72c2824b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "What is Beautiful Soup? Why is it used?\n",
    "Beautiful Soup provides simple methods for navigating, searching, and modifying a parse tree in HTML, XML files. It transforms a complex HTML document into a tree of Python objects. It also automatically converts the document to Unicode, so you don't have to think about encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ef29f5-1181-4ad1-969f-f619f1f95057",
   "metadata": {},
   "outputs": [],
   "source": [
    "Why is flask used in this Web Scraping project?\n",
    "Ans:-Flask is a lightweight framework to build websites. We'll use this to parse our collected data and display it as HTML in a new HTML file. The requests module allows us to send http requests to the website we want to scrape. The first line imports the Flask class and the render_template method from the flask library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca8572f-a5dc-4cfd-9f93-8287f9923a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    " Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "    AWS Cloud Products\n",
    "Compute.\n",
    "Storage.\n",
    "Database.\n",
    "Networking & Content Delivery.\n",
    "Analytics.\n",
    "Machine Learning.\n",
    "Security, Identity, & Complianc\n",
    "  \n",
    "List of all AWS services\n",
    "AWS Analytics Services. Amazon Athena. ...\n",
    "AWS Application Integration Services. AWS Step Functions. ...\n",
    "AWS Blockchain Services. Amazon Managed Blockchain. ...\n",
    "AWS Business Applications Services. ...\n",
    "AWS Cloud Financial Management Services. ...\n",
    "AWS Compute Services. ...\n",
    "AWS Container Services. ...\n",
    "AWS Customer Engagement Services.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
